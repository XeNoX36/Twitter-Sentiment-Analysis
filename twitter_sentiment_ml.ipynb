{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39926b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20ffbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>Tue Jun 16 18:18:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>@Nkluvr4eva My poor little dumpling  In Holmde...</td>\n",
       "      <td>nkluvr eva poor littl dumpl holmdel vid realli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Mon Apr 06 23:11:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "      <td>bed gotta wake hella earli tomorrow morn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>Tue Jun 23 13:40:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "      <td>havent abl listen yet speaker bust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>Mon Jun 01 10:26:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "      <td>rememb solv rel big equat two unknown total pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>Sat Jun 20 12:56:51 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "      <td>ate much feel sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "      <td>1971396414</td>\n",
       "      <td>Sat May 30 07:00:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>foryoutohold</td>\n",
       "      <td>as much as i wanna eat this ham sandwhich, i c...</td>\n",
       "      <td>much wanna eat ham sandwhich cant think bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>1974331845</td>\n",
       "      <td>Sat May 30 12:54:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KonkreteRose</td>\n",
       "      <td>Ok I GUESS I will stop bsing and get on the hi...</td>\n",
       "      <td>ok guess stop bsing get highway winston salem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>1966611329</td>\n",
       "      <td>Fri May 29 18:04:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>apurplepatch</td>\n",
       "      <td>@spaciireth was planning on next month, but ap...</td>\n",
       "      <td>spaciireth plan next month appar take break ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>2048348112</td>\n",
       "      <td>Fri Jun 05 15:03:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>connieyiu</td>\n",
       "      <td>at work till 2:30 tonight</td>\n",
       "      <td>work till tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "      <td>1963565198</td>\n",
       "      <td>Fri May 29 12:55:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>spunkysteph</td>\n",
       "      <td>Fkkk at the nurses coughing up my lungs</td>\n",
       "      <td>fkkk nurs cough lung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target          id                          data      flag  \\\n",
       "0           0  2200003313  Tue Jun 16 18:18:13 PDT 2009  NO_QUERY   \n",
       "1           0  1467998601  Mon Apr 06 23:11:18 PDT 2009  NO_QUERY   \n",
       "2           0  2300049112  Tue Jun 23 13:40:12 PDT 2009  NO_QUERY   \n",
       "3           0  1993474319  Mon Jun 01 10:26:09 PDT 2009  NO_QUERY   \n",
       "4           0  2256551006  Sat Jun 20 12:56:51 PDT 2009  NO_QUERY   \n",
       "...       ...         ...                           ...       ...   \n",
       "49995       0  1971396414  Sat May 30 07:00:40 PDT 2009  NO_QUERY   \n",
       "49996       0  1974331845  Sat May 30 12:54:52 PDT 2009  NO_QUERY   \n",
       "49997       0  1966611329  Fri May 29 18:04:55 PDT 2009  NO_QUERY   \n",
       "49998       0  2048348112  Fri Jun 05 15:03:23 PDT 2009  NO_QUERY   \n",
       "49999       0  1963565198  Fri May 29 12:55:00 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                               text  \\\n",
       "0       DEWGetMeTho77  @Nkluvr4eva My poor little dumpling  In Holmde...   \n",
       "1             Young_J  I'm off too bed. I gotta wake up hella early t...   \n",
       "2       dougnawoschik  I havent been able to listen to it yet  My spe...   \n",
       "3            thireven  now remembers why solving a relatively big equ...   \n",
       "4      taracollins086                           Ate too much, feel sick    \n",
       "...               ...                                                ...   \n",
       "49995    foryoutohold  as much as i wanna eat this ham sandwhich, i c...   \n",
       "49996    KonkreteRose  Ok I GUESS I will stop bsing and get on the hi...   \n",
       "49997    apurplepatch  @spaciireth was planning on next month, but ap...   \n",
       "49998       connieyiu                         at work till 2:30 tonight    \n",
       "49999     spunkysteph           Fkkk at the nurses coughing up my lungs    \n",
       "\n",
       "                                         stemmed_content  \n",
       "0      nkluvr eva poor littl dumpl holmdel vid realli...  \n",
       "1               bed gotta wake hella earli tomorrow morn  \n",
       "2                     havent abl listen yet speaker bust  \n",
       "3      rememb solv rel big equat two unknown total pa...  \n",
       "4                                     ate much feel sick  \n",
       "...                                                  ...  \n",
       "49995        much wanna eat ham sandwhich cant think bad  \n",
       "49996  ok guess stop bsing get highway winston salem ...  \n",
       "49997  spaciireth plan next month appar take break ma...  \n",
       "49998                                  work till tonight  \n",
       "49999                               fkkk nurs cough lung  \n",
       "\n",
       "[50000 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_data = pd.read_csv(r\"c:\\Users\\USER\\Documents\\CODES\\Python Work to Do\\New_twitter_Data.csv\", encoding = \"ISO-8859-1\")\n",
    "twit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfcff86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target             object\n",
       "id                  int64\n",
       "data               object\n",
       "flag               object\n",
       "user               object\n",
       "text               object\n",
       "stemmed_content    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_data[\"stemmed_content\"] = twit_data[\"stemmed_content\"].astype(str)\n",
    "twit_data[\"target\"] = twit_data[\"target\"].astype(str)\n",
    "twit_data.dropna()\n",
    "twit_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c4c6b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target             0\n",
       "id                 0\n",
       "data               0\n",
       "flag               0\n",
       "user               0\n",
       "text               0\n",
       "stemmed_content    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a1920",
   "metadata": {},
   "source": [
    "*Seperating the data and the label*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143939d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = twit_data[\"stemmed_content\"].values\n",
    "Y = twit_data[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae5da67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,) (40000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e3e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the text data into numerical data\n",
    "vectorizer = TfidfVectorizer() \n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c94f787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 296469 stored elements and shape (40000, 40612)>\n",
      "  Coords\tValues\n",
      "  (0, 16936)\t0.5125190627982731\n",
      "  (0, 39100)\t0.24073230944538737\n",
      "  (0, 36220)\t0.25147103887635314\n",
      "  (0, 13985)\t0.2821599762915316\n",
      "  (0, 20587)\t0.27256168705255585\n",
      "  (0, 11385)\t0.5125190627982731\n",
      "  (0, 35698)\t0.2821599762915316\n",
      "  (0, 14178)\t0.24110689249411676\n",
      "  (0, 33030)\t0.24861170735409296\n",
      "  (1, 24982)\t0.36611394111780404\n",
      "  (1, 3142)\t0.211315842183604\n",
      "  (1, 14074)\t0.36611394111780404\n",
      "  (1, 39378)\t0.16927492334574054\n",
      "  (1, 28566)\t0.20066851635950098\n",
      "  (1, 3361)\t0.30077492029130126\n",
      "  (1, 27918)\t0.2435335460393696\n",
      "  (1, 37972)\t0.3240491491083023\n",
      "  (1, 21020)\t0.13388379377372947\n",
      "  (1, 24969)\t0.342839712300803\n",
      "  (1, 20793)\t0.14362681136488845\n",
      "  (1, 16076)\t0.2709813956695544\n",
      "  (1, 24486)\t0.36611394111780404\n",
      "  (2, 15430)\t0.37132039494829844\n",
      "  (2, 31880)\t0.5407932490534844\n",
      "  (2, 36184)\t0.7547607740692515\n",
      "  :\t:\n",
      "  (39997, 36741)\t0.2713240623693498\n",
      "  (39997, 39531)\t0.21450213740817717\n",
      "  (39997, 27309)\t0.23384233888743536\n",
      "  (39997, 14398)\t0.37976718443871704\n",
      "  (39997, 9620)\t0.37976718443871704\n",
      "  (39997, 39663)\t0.37976718443871704\n",
      "  (39998, 15227)\t0.17868778010716665\n",
      "  (39998, 13619)\t0.16444070237416597\n",
      "  (39998, 21244)\t0.23918218964587085\n",
      "  (39998, 31341)\t0.1694419011717702\n",
      "  (39998, 11360)\t0.24521446200851743\n",
      "  (39998, 28440)\t0.32095840102330536\n",
      "  (39998, 12796)\t0.27229985650882377\n",
      "  (39998, 8292)\t0.14393737228524783\n",
      "  (39998, 12092)\t0.24128484656911528\n",
      "  (39998, 2315)\t0.2602395315306009\n",
      "  (39998, 5676)\t0.3543355479456604\n",
      "  (39998, 36155)\t0.4156951869295551\n",
      "  (39998, 11036)\t0.4156951869295551\n",
      "  (39999, 20793)\t0.20113694263466686\n",
      "  (39999, 27352)\t0.28310915830525396\n",
      "  (39999, 33544)\t0.39786556689279334\n",
      "  (39999, 3683)\t0.4419853965916047\n",
      "  (39999, 23333)\t0.512710949108807\n",
      "  (39999, 32668)\t0.512710949108807\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8709870",
   "metadata": {},
   "source": [
    "*Training the ML model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3a4b3",
   "metadata": {},
   "source": [
    "*Logistic Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fbd7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, Y_train)\n",
    "X_train_prediction = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e1ce49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835225"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the accuracy of the model\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aef7fdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7503"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the ML-prediction and accuracy score of the test set\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "test_data_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f126ef87",
   "metadata": {},
   "source": [
    "*Saving the trained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3356a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = \"trained_model.sav\"\n",
    "pickle.dump(model, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81a94073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadong the saved model\n",
    "loaded_model = pickle.load(open(\"trained_model.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16452e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Correct, Positive Tweet\n"
     ]
    }
   ],
   "source": [
    "# applying the model for data prediction\n",
    "X_new = X_test[200]\n",
    "print(Y_test[200])\n",
    "prediction = loaded_model.predict(X_new)\n",
    "\n",
    "if prediction == 0:\n",
    "    print(\"Negative Tweet\")\n",
    "else:\n",
    "    print(\"Correct, Positive Tweet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
